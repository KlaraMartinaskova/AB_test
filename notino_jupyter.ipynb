{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notino Test Assigment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notino Test Assigment\n",
    "# Author: Klara Martinaskova\n",
    "# Task: Evaluate an AB test of the recommendation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3.9\n",
    "# coding=utf-8\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pingouin as pg\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open csv file ans save as dataframe\n",
    "df_clients = pd.read_csv(\n",
    "    \"clients_final.csv\", encoding=\"cp1250\", sep=\",\", low_memory=False)\n",
    "df_orders = pd.read_csv(\n",
    "    \"orders_final.csv\", encoding=\"cp1250\", sep=\",\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in abUser: [ 1.  2. nan]\n"
     ]
    }
   ],
   "source": [
    "# Analysis of abUser column\n",
    "# 99 is not present here (just NaN)\n",
    "abUser_unique = df_clients[\"abUser\"].unique()\n",
    "txt = \"Unique values in abUser: {}\"\n",
    "print(txt.format(abUser_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devided into two groups by country\n",
    "df_clients_ch = df_clients[df_clients[\"country\"] == \"CH\"]\n",
    "df_clients_ne = df_clients[df_clients[\"country\"] == \"NE\"]\n",
    "\n",
    "df_orders_ch = df_orders[df_orders[\"country\"] == \"CH\"]\n",
    "df_orders_ne = df_orders[df_orders[\"country\"] == \"NE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klara\\AppData\\Local\\Temp\\ipykernel_21004\\1692912779.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
      "C:\\Users\\klara\\AppData\\Local\\Temp\\ipykernel_21004\\1692912779.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"date\"] = filtered_df[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
      "C:\\Users\\klara\\AppData\\Local\\Temp\\ipykernel_21004\\1692912779.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"date\"] = pd.to_datetime(df[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "# Check the date\n",
    "# Is the test running for the correct period?\n",
    "\n",
    "\n",
    "def filter_by_period(df, start_date, end_date):\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    filtered_df = df[(df[\"date\"] >= start_date) & (df[\"date\"] <= end_date)]\n",
    "    filtered_df[\"date\"] = filtered_df[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "start_date = datetime(2023, 5, 17)\n",
    "end_date = datetime(2023, 6, 16)\n",
    "\n",
    "df_clients_ch = filter_by_period(\n",
    "    df_clients_ch, start_date, end_date)  # data in correct period\n",
    "df_clients_ne = filter_by_period(\n",
    "    df_clients_ne, start_date, end_date)  # data in correct period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only unique clientID\n",
    "# Sort dataframe by date\n",
    "df_clients_ch = df_clients_ch.sort_values(by=[\"date\"])\n",
    "df_clients_ne = df_clients_ne.sort_values(by=[\"date\"])\n",
    "\n",
    "# Save raw data\n",
    "df_clients_ch_raw = df_clients_ch.copy()\n",
    "df_clients_ne_raw = df_clients_ne.copy()\n",
    "\n",
    "# Drop duplicated client id and keep the first one\n",
    "df_clients_ch = df_clients_ch.drop_duplicates(\n",
    "    subset=[\"clientID\"], keep=\"first\")\n",
    "df_clients_ne = df_clients_ne.drop_duplicates(\n",
    "    subset=[\"clientID\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicates and NaN in orders\n",
    "\n",
    "df_orders_ch = df_orders_ch.drop_duplicates(\n",
    "    subset=[\"orderNumber\"], keep=\"first\")  # drop duplicates\n",
    "df_orders_ch = df_orders_ch.dropna(subset=[\"orderNumber\"])  # drop NaN\n",
    "\n",
    "df_orders_ne = df_orders_ne.drop_duplicates(\n",
    "    subset=[\"orderNumber\"], keep=\"first\")  # drop duplicates\n",
    "df_orders_ne = df_orders_ne.dropna(subset=[\"orderNumber\"])  # drop NaN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Is the ratio of users in the reco group and users in the test group really 50:50? \n",
    "###### Can you test it by an appropriate statistical test? \n",
    "######  Do you prefer to test it on a daily basis, or to run one test for the whole period? \n",
    "######  If you run multiple tests, do you need all of them to have positive results to verify the 50:50 distribution hypothesis? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_test(df_group1, df_group2, expected_proportion, alt):\n",
    "    observed_success = len(df_group1)\n",
    "    total_items = len(df_group1) + len(df_group2)\n",
    "    return stats.binomtest(observed_success, total_items, expected_proportion, alternative=alt)\n",
    "\n",
    "\n",
    "def filter_by_day_and_abUser(df, day, abUser):\n",
    "    return df[(df[\"date\"] == unique_days[day]) & (df[\"abUser\"] == abUser)]\n",
    "\n",
    "\n",
    "def check_share_of_abUser_each_day(df, unique_days):\n",
    "    for day in range(len(unique_days)):\n",
    "        df_current_day_reco = filter_by_day_and_abUser(df, day, 1)\n",
    "        df_current_day_control = filter_by_day_and_abUser(df, day, 2)\n",
    "        expected_share = 0.5\n",
    "        binom = binomial_test(df_current_day_reco,\n",
    "                              df_current_day_control, expected_share, \"two-sided\")\n",
    "\n",
    "        if binom.pvalue < 0.05:\n",
    "            print(f\"\\tDay {unique_days[day]} is significant\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test if the ratio of users in the reco group and users in the test group really 50:50\n",
      "\n",
      "Days with significant p-values for CH (if any): \n",
      "Days with significant p-values for NE (if any): \n",
      "\tDay 2023-05-25 is significant\n",
      "\tDay 2023-05-29 is significant\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test for each day\n",
    "print(\"Test if the ratio of users in the reco group and users in the test group really 50:50\\n\")\n",
    "\n",
    "# CH\n",
    "unique_days = df_clients_ch[\"date\"].unique()\n",
    "\n",
    "print(\"Days with significant p-values for CH (if any): \")\n",
    "check_share_of_abUser_each_day(df_clients_ch, unique_days)\n",
    "\n",
    "# NE\n",
    "unique_days = df_clients_ne[\"date\"].unique()\n",
    "\n",
    "print(\"Days with significant p-values for NE (if any): \")\n",
    "check_share_of_abUser_each_day(df_clients_ne, unique_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ration for whole period: \n",
      "Binomial test for CH: BinomTestResult(k=1031241, n=2062236, alternative='two-sided', statistic=0.5000596439980681, pvalue=0.8645327813601438)\n",
      "\tThe test is not significant\n",
      "Binomial test for NE: BinomTestResult(k=227493, n=453869, alternative='two-sided', statistic=0.5012305312766459, pvalue=0.09761471403682057)\n",
      "\tThe test is not significant\n"
     ]
    }
   ],
   "source": [
    "# Test for whole period\n",
    "print(\"Test ration for whole period: \")\n",
    "share = 0.5\n",
    "\n",
    "# CH\n",
    "df_clients_ch_reco = df_clients_ch[\"abUser\"][df_clients_ch[\"abUser\"] == 1]\n",
    "df_clients_ch_control = df_clients_ch[\"abUser\"][df_clients_ch[\"abUser\"] == 2]\n",
    "\n",
    "binom_ch = binomial_test(\n",
    "    df_clients_ch_reco, df_clients_ch_control, share, \"two-sided\")\n",
    "\n",
    "print(f\"Binomial test for CH: {binom_ch}\")\n",
    "\n",
    "if binom_ch.pvalue < 0.05:\n",
    "    print(\"\\tThe test is significant\")\n",
    "else:\n",
    "    print(\"\\tThe test is not significant\")\n",
    "\n",
    "# NE\n",
    "df_clients_ne_reco = df_clients_ne[\"abUser\"][df_clients_ne[\"abUser\"] == 1]\n",
    "df_clients_ne_control = df_clients_ne[\"abUser\"][df_clients_ne[\"abUser\"] == 2]\n",
    "\n",
    "binom_ne = binomial_test(\n",
    "    df_clients_ne_reco, df_clients_ne_control, share, \"two-sided\")\n",
    "\n",
    "print(f\"Binomial test for NE: {binom_ne}\")\n",
    "\n",
    "if binom_ne.pvalue < 0.05:\n",
    "    print(\"\\tThe test is significant\")\n",
    "else:\n",
    "    print(\"\\tThe test is not significant\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What about the users with an unassigned group? Bambino thinks the test is fine if their share is below 0.5%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unassigned count:  12206\n"
     ]
    }
   ],
   "source": [
    "df = df_clients_ch\n",
    "unassigned_count = len(df[\"abUser\"][(df[\"abUser\"] != 1) & (df[\"abUser\"] != 2)])\n",
    "\n",
    "print(\"Unassigned count: \", unassigned_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of users with an unassigned group for CH: \n",
      "\tThe test is not fine, share is 0.59%\n",
      "Share of users with an unassigned group for NE: \n",
      "\tThe test is not fine, share is 0.53%\n"
     ]
    }
   ],
   "source": [
    "# First method without statistical test\n",
    "\n",
    "def unassigned_share(df):\n",
    "    reco_count = df[\"abUser\"][df[\"abUser\"] == 1].count()\n",
    "    control_count = df[\"abUser\"][df[\"abUser\"] == 2].count()\n",
    "\n",
    "    unassigned_count = len(\n",
    "        df[\"abUser\"][(df[\"abUser\"] != 1) & (df[\"abUser\"] != 2)])\n",
    "    unnasigned_percent_share = unassigned_count / \\\n",
    "        ((reco_count + control_count + unassigned_count))*100\n",
    "\n",
    "    if unnasigned_percent_share < 0.5:\n",
    "        print(\"\\tThe test is fine, share is below 0.5%.\")\n",
    "        print(\n",
    "            \"\\tPercent of users with an unassigned group: {:.2f}%\".format(unnasigned_percent_share))\n",
    "    else:\n",
    "        print(\"\\tThe test is not fine, share is {:.2f}%\".format(\n",
    "            unnasigned_percent_share))\n",
    "print(\"Share of users with an unassigned group for CH: \")\n",
    "unassigned_share(df_clients_ch)\n",
    "\n",
    "print(\"Share of users with an unassigned group for NE: \")\n",
    "unassigned_share(df_clients_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binomial test for CH: \n",
      "\tBinomTestResult(k=12206, n=2074442, alternative='less', statistic=0.005883991936144756, pvalue=1.0)\n",
      "\tThe test is not significant.\n",
      "Binomial test for NE: \n",
      "\tBinomTestResult(k=2398, n=456267, alternative='less', statistic=0.00525569458233885, pvalue=0.9926992491834234)\n",
      "\tThe test is not significant.\n"
     ]
    }
   ],
   "source": [
    "# Second method with statistical test\n",
    "share_unassigned = 0.005\n",
    "# CH\n",
    "assigned_group_ch = df_clients_ch[\"abUser\"][(\n",
    "    df_clients_ch[\"abUser\"] == 1) | (df_clients_ch[\"abUser\"] == 2)]\n",
    "unassigned_group_ch = df_clients_ch[\"abUser\"][(\n",
    "    df_clients_ch[\"abUser\"] != 1) & (df_clients_ch[\"abUser\"] != 2)]\n",
    "binom_ch = binomial_test(\n",
    "    unassigned_group_ch, assigned_group_ch, share_unassigned, \"less\")\n",
    "\n",
    "print(f\"Binomial test for CH: \\n\\t{binom_ch}\")\n",
    "if binom_ch.pvalue < 0.05:\n",
    "    print(\"\\tThe test is significant.\")\n",
    "else:\n",
    "    print(\"\\tThe test is not significant.\")\n",
    "\n",
    "# NE\n",
    "assigned_group_ne = df_clients_ne[\"abUser\"][(\n",
    "    df_clients_ne[\"abUser\"] == 1) | (df_clients_ne[\"abUser\"] == 2)]\n",
    "unassigned_group_ne = df_clients_ne[\"abUser\"][(\n",
    "    df_clients_ne[\"abUser\"] != 1) & (df_clients_ne[\"abUser\"] != 2)]\n",
    "binom_ne = binomial_test(\n",
    "    unassigned_group_ne, assigned_group_ne, share_unassigned, \"less\")\n",
    "\n",
    "print(f\"Binomial test for NE: \\n\\t{binom_ne}\")\n",
    "if binom_ne.pvalue < 0.05:\n",
    "    print(\"\\tThe test is significan.t\")\n",
    "else:\n",
    "    print(\"\\tThe test is not significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unassigned user record\n",
    "df_clients_ch = df_clients_ch[(df_clients_ch[\"abUser\"] == 1) | (\n",
    "    df_clients_ch[\"abUser\"] == 2)]\n",
    "df_clients_ne = df_clients_ne[(df_clients_ne[\"abUser\"] == 1) | (\n",
    "    df_clients_ne[\"abUser\"] == 2)]\n",
    "\n",
    "df_clients_ch_raw = df_clients_ch_raw[(\n",
    "    df_clients_ch_raw[\"abUser\"] == 1) | (df_clients_ch_raw[\"abUser\"] == 2)]\n",
    "df_clients_ne_raw = df_clients_ne_raw[(\n",
    "    df_clients_ne_raw[\"abUser\"] == 1) | (df_clients_ne_raw[\"abUser\"] == 2)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What about the orders that are not in GA data? What is their share? How do you propose to handle them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CH\n",
    "df_join_ch = df_clients_ch_raw.merge(\n",
    "    df_orders_ch, on=\"orderNumber\", how=\"inner\")  # join tables (inner join)\n",
    "share_orders_not_in_GA_ch = 1 - \\\n",
    "    (len(df_join_ch) / len(df_orders_ch))  # share of orders not in GA\n",
    "\n",
    "print(\"Share of orders that are not in GA data for CH: {:.2f}%\".format(\n",
    "    share_orders_not_in_GA_ch * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NE\n",
    "df_join_ne = df_clients_ne_raw.merge(\n",
    "    df_orders_ne, on=\"orderNumber\", how=\"inner\")  # join tables (inner join)\n",
    "share_orders_not_in_GA_ne = 1 - \\\n",
    "    (len(df_join_ne) / len(df_orders_ne))  # share of orders not in GA\n",
    "\n",
    "print(\"Share of orders that are not in GA data for NE: {:.2f}%\".format(\n",
    "    share_orders_not_in_GA_ne * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Does the “reco group” earn, on average, a greater revenue? Does it have larger orders?\n",
    "###### Propose appropriate metrics and visualize them. Is there any other metric you may wish to evaluate?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reco group:  abUser == 1\n",
    "# control group: abUser == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test(group1, group2):\n",
    "    ttest_result = stats.ttest_ind(a=group1, b=group2, equal_var=True)\n",
    "    print(\"\\tT-test p-value: \", ttest_result.pvalue)\n",
    "\n",
    "    if ttest_result.pvalue < 0.05:\n",
    "        print(\"\\tThe difference between the two groups is statistically significant.\")\n",
    "    else:\n",
    "        print(\"\\tThe difference between the two groups is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Revenue\n",
    "print(\"Test if the “reco group” earn, on average, a greater revenue: \")\n",
    "# CH\n",
    "df_reco = df_join_ch[\"revenue\"][df_join_ch[\"abUser\"] == 1]\n",
    "df_control = df_join_ch[\"revenue\"][df_join_ch[\"abUser\"] == 2]\n",
    "\n",
    "print(\"Test for country CH: \")\n",
    "\n",
    "t_test(df_reco, df_control)\n",
    "\n",
    "# NE\n",
    "df_reco = df_join_ne[\"revenue\"][df_join_ne[\"abUser\"] == 1]\n",
    "df_control = df_join_ne[\"revenue\"][df_join_ne[\"abUser\"] == 2]\n",
    "\n",
    "print(\"Test for country NE: \")\n",
    "\n",
    "t_test(df_reco, df_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Quantity\n",
    "print(\"Test if the “reco group” has larger order: \")\n",
    "# CH\n",
    "df_reco = df_join_ch[\"quantity\"][df_join_ch[\"abUser\"] == 1]\n",
    "df_control = df_join_ch[\"quantity\"][df_join_ch[\"abUser\"] == 2]\n",
    "print(\"Test for country CH: \")\n",
    "t_test(df_reco, df_control)\n",
    "\n",
    "# NE\n",
    "df_reco = df_join_ne[\"quantity\"][df_join_ne[\"abUser\"] == 1]\n",
    "df_control = df_join_ne[\"quantity\"][df_join_ne[\"abUser\"] == 2]\n",
    "print(\"Test for country NE: \")\n",
    "t_test(df_reco, df_control)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Check the distribution of the data for quantity and revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CH\n",
    "df_join = df_join_ch\n",
    "plt.scatter(df_join[\"quantity\"][df_join[\"abUser\"] == 1],\n",
    "            df_join[\"revenue\"][df_join[\"abUser\"] == 1], alpha=0.5, marker=\"o\")\n",
    "plt.scatter(df_join[\"quantity\"][df_join[\"abUser\"] == 2],\n",
    "            df_join[\"revenue\"][df_join[\"abUser\"] == 2], alpha=0.5, marker=\"o\")\n",
    "plt.xlabel(\"Quantity - number of items in the order\")\n",
    "plt.ylabel(\"Revenue [EUR]\")\n",
    "plt.legend([\"Reco Group\", \"Control Group\"])\n",
    "plt.title(\n",
    "    \"Distruibution of revenue and quantity \\n for reco and control group for country CH\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NE\n",
    "df_join = df_join_ne\n",
    "plt.scatter(df_join[\"quantity\"][df_join[\"abUser\"] == 1],\n",
    "            df_join[\"revenue\"][df_join[\"abUser\"] == 1], alpha=0.5, marker=\"o\")\n",
    "plt.scatter(df_join[\"quantity\"][df_join[\"abUser\"] == 2],\n",
    "            df_join[\"revenue\"][df_join[\"abUser\"] == 2], alpha=0.5, marker=\"o\")\n",
    "plt.xlabel(\"Quantity - number of items in the order\")\n",
    "plt.ylabel(\"Revenue [EUR]\")\n",
    "plt.legend([\"Reco Group\", \"Control Group\"])\n",
    "plt.title(\n",
    "    \"Distruibution of revenue and quantity \\n for reco and control for country NE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outlier from NE dataframe\n",
    "reco_max = df_join_ne[\"revenue\"][df_join_ne[\"abUser\"] == 1].idxmax()\n",
    "# df_join_ne_with_outlier = df_join_ne.copy()\n",
    "df_join_ne = df_join_ne.drop(reco_max)  # redefine dataframe without outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of distribution without outlier\n",
    "df_join = df_join_ne\n",
    "plt.scatter(df_join[\"quantity\"][df_join[\"abUser\"] == 1],\n",
    "            df_join[\"revenue\"][df_join[\"abUser\"] == 1], alpha=0.5, marker=\"o\")\n",
    "plt.scatter(df_join[\"quantity\"][df_join[\"abUser\"] == 2],\n",
    "            df_join[\"revenue\"][df_join[\"abUser\"] == 2], alpha=0.5, marker=\"o\")\n",
    "plt.xlabel(\"Quantity - number of items in the order\")\n",
    "plt.ylabel(\"Revenue [EUR]\")\n",
    "plt.legend([\"Reco Group\", \"Control Group\"])\n",
    "plt.title(\"Distruibution of revenue and quantity \\n for reco and control for country NE without outlier\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CH\n",
    "# Boxplot for revenue\n",
    "sns.boxplot(data=df_join_ch, x=\"abUser\", y=\"revenue\")\n",
    "plt.ylabel(\"Revenue [EUR]\")\n",
    "plt.title(\"Country CH \\nBox Plot for Reco and Control Group - Revenue\")\n",
    "plt.xticks([0, 1], [\"Reco Group\", \"Control Group\"])\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for quantity\n",
    "sns.boxplot(data=df_join_ne, x=\"abUser\", y=\"quantity\")\n",
    "plt.ylabel(\"Number of items in the order\")\n",
    "plt.title(\"Country CH \\nBox Plot for Reco and Control Group - Quantity\")\n",
    "plt.xticks([0, 1], [\"Reco Group\", \"Control Group\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NE\n",
    "# Boxplot for revenue\n",
    "sns.boxplot(data=df_join_ne, x=\"abUser\", y=\"revenue\")\n",
    "plt.ylabel(\"Revenue [EUR]\")\n",
    "plt.title(\"Country NE \\nBox Plot for Reco and Control Group - Revenue\")\n",
    "plt.xticks([0, 1], [\"Reco Group\", \"Control Group\"])\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for quantity\n",
    "sns.boxplot(data=df_join_ne, x=\"abUser\", y=\"quantity\")\n",
    "plt.ylabel(\"Number of items in the order\")\n",
    "plt.title(\"Country NE \\nBox Plot for Reco and Control Group - Quantity\")\n",
    "plt.xticks([0, 1], [\"Reco Group\", \"Control Group\"])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Histograms - frequency of occurence (CH country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CH\n",
    "df_join = df_join_ch\n",
    "\n",
    "# Histogram for quantity\n",
    "plt.hist(x=df_join[\"quantity\"][df_join[\"abUser\"] == 1],\n",
    "         bins=100,  alpha=0.5, label=\"reco group\")\n",
    "plt.hist(x=df_join[\"quantity\"][df_join[\"abUser\"] == 2],\n",
    "         bins=100,  alpha=0.5, label=\"control group\")\n",
    "plt.xlabel(\"Quantity - number of items in the order\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend([\"Reco Group\", \"Control Group\"])\n",
    "plt.title(\"Country CH \\nHistogram of quantity for reco and control group\")\n",
    "plt.show()\n",
    "\n",
    "# Histogram for revenue\n",
    "plt.hist(x=df_join[\"revenue\"][df_join[\"abUser\"] == 1],\n",
    "         bins=100,  alpha=0.5, label=\"reco group\")\n",
    "plt.hist(x=df_join[\"revenue\"][df_join[\"abUser\"] == 2],\n",
    "         bins=100,  alpha=0.5, label=\"control group\")\n",
    "plt.xlabel(\"Revenue [EUR]\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend([\"Reco Group\", \"Control Group\"])\n",
    "plt.title(\"Country CH \\nHistogram of revenue for reco and control group\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average item revenue by order size (CH country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CH\n",
    "\n",
    "# Visualization of average revenue by quantity\n",
    "grouped_data = df_join.groupby([\"quantity\", \"abUser\"])[\n",
    "    \"revenue\"].mean().unstack()\n",
    "\n",
    "ax = grouped_data.plot(kind=\"bar\", alpha=0.7)\n",
    "ax.set_title(\"Country CH \\nAverage item revenue by order size\")\n",
    "ax.set_ylabel(\"Average item price [EUR]\")\n",
    "ax.set_xlabel(\"Quantity - number of items in the order\")\n",
    "plt.legend([\"Reco Group\", \"Control Group\"])\n",
    "plt.show()\n",
    "\n",
    "# Visualization of average revenue by quantity for most common quantity\n",
    "filtered_df = df_join[df_join[\"quantity\"].between(1, 10)]\n",
    "grouped_data_filtered = filtered_df.groupby([\"quantity\", \"abUser\"])[\n",
    "    \"revenue\"].mean().unstack()\n",
    "\n",
    "ax = grouped_data_filtered.plot(kind=\"bar\", alpha=0.7)\n",
    "ax.set_title(\"Country CH \\nAverage item revenue by order size\")\n",
    "ax.set_ylabel(\"Average item price [EUR]\")\n",
    "ax.set_xlabel(\"Quantity - number of items in the order\")\n",
    "plt.legend([\"Reco Group\", \"Control Group\"])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Histograms - frequency of occurence (NE country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NE\n",
    "df_join = df_join_ne\n",
    "\n",
    "# Histogram for quantity\n",
    "plt.hist(x=df_join[\"quantity\"][df_join[\"abUser\"] == 1],\n",
    "         bins=100,  alpha=0.5, label=\"reco group\")\n",
    "plt.hist(x=df_join[\"quantity\"][df_join[\"abUser\"] == 2],\n",
    "         bins=100,  alpha=0.5, label=\"control group\")\n",
    "plt.xlabel(\"Quantity - number of items in the order\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend([\"Reco Group\", \"Control Group\"])\n",
    "plt.title(\"Country NE \\nHistogram of quantity for reco and control group\")\n",
    "plt.show()\n",
    "\n",
    "# Histogram for revenue\n",
    "plt.hist(x=df_join[\"revenue\"][df_join[\"abUser\"] == 1],\n",
    "         bins=100,  alpha=0.5, label=\"reco group\")\n",
    "plt.hist(x=df_join[\"revenue\"][df_join[\"abUser\"] == 2],\n",
    "         bins=100,  alpha=0.5, label=\"control group\")\n",
    "plt.xlabel(\"Revenue [EUR]\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend([\"Reco Group\", \"Control Group\"])\n",
    "plt.title(\"Country NE \\nHistogram of revenue for reco and control group\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average item revenue by order size (NE country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of average revenue by quantity\n",
    "grouped_data = df_join.groupby([\"quantity\", \"abUser\"])[\n",
    "    \"revenue\"].mean().unstack()\n",
    "\n",
    "ax = grouped_data.plot(kind=\"bar\", alpha=0.7)\n",
    "ax.set_title(\"Country NE \\nAverage item revenue by order size\")\n",
    "ax.set_ylabel(\"Average item price [EUR]\")\n",
    "ax.set_xlabel(\"Quantity - number of items in the order\")\n",
    "plt.legend([\"Reco Group\", \"Control Group\"])\n",
    "plt.show()\n",
    "\n",
    "# Visualization of average revenue by quantity for most common quantity\n",
    "filtered_df = df_join[df_join[\"quantity\"].between(1, 10)]\n",
    "grouped_data_filtered = filtered_df.groupby([\"quantity\", \"abUser\"])[\n",
    "    \"revenue\"].mean().unstack()\n",
    "\n",
    "ax = grouped_data_filtered.plot(kind=\"bar\", alpha=0.7)\n",
    "ax.set_title(\"Country NE \\nAverage item revenue by order size\")\n",
    "ax.set_ylabel(\"Average item price [EUR]\")\n",
    "ax.set_xlabel(\"Quantity - number of items in the order\")\n",
    "plt.legend([\"Reco Group\", \"Control Group\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
